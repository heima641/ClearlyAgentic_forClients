#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Video Script Automation Workflow Script with Quote Distribution & Professional Competence

This script processes Poppy Card content and generates video scripts using:
- Voice guidance (tone and style)
- Method guidance (structure and framework) 
- Prompt instructions (specific processing directions)
- Poppy Card content (unique subject matter)

ENHANCEMENTS:
- Strategic quote distribution (12-15 quotes per script)
- Peer validation psychology framework
- Professional competence vs. ego-stroking detection
- Quote distribution validation and reporting

The workflow processes 10 predefined Poppy Card combinations sequentially,
generating custom video scripts for each combination and saving them to Supabase.

All output files are saved to Supabase Storage buckets.
"""

# =====================================================================
# COMMON IMPORTS AND SETUP
# =====================================================================

import os
import json
import re
import time
import traceback
import logging
from datetime import datetime
from zoneinfo import ZoneInfo

# Import OpenAI for script generation
import openai

# SUP BUCKET OUTPUT SUP BUCKET OUTPUT
from dotenv import load_dotenv
from supabase import create_client  # # SUPABASE BUCKET: import Supabase client
from supabase import Client

# =====================================================================
# CONSTANTS AND CONFIGURATION
# =====================================================================

# Script directory for use in file path construction
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# Path to environment variables file
ENV_FILE_PATH = "STATIC_VARS_MAR2025.env"

# SUP BUCKET OUTPUT SUP BUCKET OUTPUT
# Load environment variables (for any additional env vars needed)
load_dotenv(ENV_FILE_PATH)
supabase_url = os.getenv("VITE_SUPABASE_URL")
supabase_service_key = os.getenv("VITE_SUPABASE_SERVICE_ROLE_KEY")

# Handle missing environment variables
if not supabase_url or not supabase_service_key:
    print("Error: Missing Supabase credentials")
    exit(1)

supabase = create_client(supabase_url, supabase_service_key)
openai_api_key = os.getenv("OPENAI_API_KEY")

# Record start time for execution tracking (Eastern Time)
eastern_tz = ZoneInfo("America/New_York")
start_time = datetime.now(eastern_tz)

# Default retry settings
DEFAULT_MAX_RETRIES = 3
DEFAULT_RETRY_DELAY = 2  # seconds

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f"video_script_log_{datetime.now(eastern_tz).strftime('%Y%m%d_%H%M%S')}.log")
    ])
logger = logging.getLogger(__name__)

# Suppress excessive HTTP request logs
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)

# Setup directory structure
script_dir = os.path.dirname(os.path.abspath(__file__))
ENV_FILE_PATH = os.path.join(script_dir, "STATIC_VARS_MAR2025.env")

# =====================================================================
# COMMON FUNCTIONS
# =====================================================================

def fetch_configuration_from_supabase(config_name=None, config_id=None):
    """
    Fetch configuration variables from Supabase workflow_configs table

    Args:
        config_name (str, optional): Name of the configuration to fetch
        config_id (int, optional): ID of the configuration to fetch

    Returns:
        dict: Configuration variables
    """
    try:
        # Use the global Supabase client
        global supabase

        # Query based on either name or ID
        if config_id:
            print(f"Fetching configuration with ID: {config_id}")
            response = supabase.table("workflow_configs").select("*").eq(
                "id", config_id).execute()
        elif config_name:
            print(f"Fetching configuration with name: {config_name}")
            response = supabase.table("workflow_configs").select("*").eq(
                "config_name", config_name).execute()
        else:
            # If no specific config requested, get the most recent one
            print("Fetching most recent configuration")
            response = supabase.table("workflow_configs").select("*").order(
                "created_at", desc=True).limit(1).execute()

        # Check if we got any data
        if not response.data or len(response.data) == 0:
            print("No configuration found in Supabase")
            raise Exception("No configuration found in Supabase")

        # Return the variables from the first matching record
        config_data = response.data[0]
        print(
            f"Successfully fetched configuration: {config_data.get('config_name', 'unnamed')}"
        )
        return config_data.get("variables", {})

    except Exception as e:
        print(f"Error fetching configuration from Supabase: {str(e)}")
        raise


def download_file_from_bucket(bucket_name, file_name):
    """
    Download a file from Supabase storage bucket
    
    Args:
        bucket_name (str): Name of the Supabase bucket
        file_name (str): Name of the file to download
        
    Returns:
        str: File content as string
    """
    try:
        print(f"Downloading {file_name} from {bucket_name} bucket...")
        response = supabase.storage.from_(bucket_name).download(file_name)

        if response:
            content = response.decode('utf-8')
            print(
                f"Successfully downloaded {file_name} ({len(content)} characters)"
            )
            return content
        else:
            raise Exception(f"Failed to download {file_name}")

    except Exception as e:
        print(f"Error downloading {file_name} from {bucket_name}: {str(e)}")
        raise


def upload_file_to_bucket(bucket_name, file_name, file_content):
    """
    Upload a file to Supabase storage bucket
    
    Args:
        bucket_name (str): Name of the Supabase bucket
        file_name (str): Name of the file to upload
        file_content (str): Content to upload
        
    Returns:
        bool: True if successful
    """
    try:
        print(f"Uploading {file_name} to {bucket_name} bucket...")

        # Convert string content to bytes
        file_bytes = file_content.encode('utf-8')

        response = supabase.storage.from_(bucket_name).upload(
            file_name, file_bytes, {"content-type": "text/plain"})

        print(f"Successfully uploaded {file_name} to {bucket_name}")
        return True

    except Exception as e:
        print(f"Error uploading {file_name} to {bucket_name}: {str(e)}")
        raise


# =====================================================================
# ENHANCED QUOTE DISTRIBUTION VALIDATION FUNCTION
# =====================================================================

def validate_quote_distribution(script_content):
    """
    Validate that the generated script has proper quote distribution for optimal conversion psychology
    
    Args:
        script_content (str): The generated video script content
        
    Returns:
        tuple: (is_valid: bool, message: str)
    """
    try:
        # Count total quotes in the script
        quote_count = len(re.findall(r'"[^"]*"', script_content))
        
        # Target: 12-15 quotes for optimal psychological impact
        if quote_count < 10:
            return False, f"Insufficient quotes: {quote_count} (target: 12-15 for optimal conversion psychology)"
        elif quote_count > 20:
            return False, f"Too many quotes: {quote_count} (target: 12-15 for optimal readability)"
        
        # Check for quotes in problem sections
        # Look for common problem indicators
        problem_sections = re.split(r'(?i)(problem|challenge|issue|struggle|difficulty)', script_content)
        
        if len(problem_sections) > 1:  # If we found problem sections
            quotes_in_problems = 0
            for section in problem_sections[1:]:  # Skip the intro before first problem
                # Look for quotes in the next 300 characters after problem indicator
                section_preview = section[:300] if len(section) >= 300 else section
                quotes_in_section = len(re.findall(r'"[^"]*"', section_preview))
                if quotes_in_section > 0:
                    quotes_in_problems += 1
            
            if quotes_in_problems < 2:
                return False, f"Insufficient quotes in problem sections: {quotes_in_problems} (need quotes in each problem for credibility)"
        
        # Check for professional competence indicators (not ego-stroking)
        ego_indicators = ['hero', 'genius', 'star', 'rockstar', 'superstar', 'legend', 'champion']
        confidence_indicators = ['confident', 'prepared', 'clarity', 'insights', 'data-driven', 'strategic']
        
        ego_count = sum(1 for word in ego_indicators if word in script_content.lower())
        confidence_count = sum(1 for word in confidence_indicators if word in script_content.lower())
        
        if ego_count > confidence_count:
            return False, f"Script leans toward ego-stroking ({ego_count} ego vs {confidence_count} confidence indicators). Focus on professional competence instead."
        
        # Success validation
        return True, f"Excellent quote distribution: {quote_count} total quotes with professional competence focus"
        
    except Exception as e:
        return False, f"Validation error: {str(e)}"


# =====================================================================
# ENHANCED VIDEO SCRIPT GENERATION FUNCTION
# =====================================================================

def generate_video_script(voice_guidance,
                          method_guidance,
                          prompt_instructions,
                          poppy_card_content,
                          openai_model="gpt-4o",
                          max_retries=3,
                          retry_delay=2):
    """
    Generate a video script using OpenAI API with enhanced quote distribution and peer validation
    
    Args:
        voice_guidance (str): Voice and tone guidance
        method_guidance (str): Script structure and framework guidance
        prompt_instructions (str): Specific processing instructions
        poppy_card_content (str): Poppy Card content to focus on
        openai_model (str): OpenAI model to use
        max_retries (int): Maximum number of retry attempts
        retry_delay (int): Delay between retries in seconds
        
    Returns:
        str: Generated video script with enhanced quote distribution
    """
    try:
        # Create OpenAI client
        client = openai.OpenAI(api_key=openai_api_key)

        # ‚úÖ ENHANCED SYSTEM PROMPT WITH STRATEGIC QUOTE DISTRIBUTION
        system_prompt = f"""You are a professional video script writer specializing in B2B software buyer psychology. Generate a video script using the following guidance:

VOICE GUIDELINES:
{voice_guidance}

SCRIPT METHOD/FRAMEWORK:
{method_guidance}

SPECIFIC INSTRUCTIONS:
{prompt_instructions}

CONTENT TO FOCUS ON:
{poppy_card_content}

STRATEGIC QUOTE DISTRIBUTION REQUIREMENTS:
- Include customer quotes in EVERY problem section for maximum credibility
- Structure each problem with: Problem Introduction ‚Üí Customer Quote validating the problem ‚Üí Solution + Benefits ‚Üí Success Quote
- Use role-specific attributions (Director of Sales, VP Sales, CRO, CEO) to broaden buyer persona appeal
- Distribute quotes every 60-90 seconds throughout the script for continuous social proof
- Target 12-15 total quotes across the script for optimal conversion psychology

PSYCHOLOGICAL FRAMEWORK - PEER VALIDATION APPROACH:
- Frame this as "peer sharing insights" rather than "company selling solution"
- Each problem should feel like: "Here's what other companies like yours are struggling with"
- Each solution should feel like: "Here's how companies just like yours solved this exact issue"
- Use customer quotes to create "social proof bridges" that connect problems to solutions
- Make viewers think: "This isn't a sales pitch - these are real peer experiences"
- Emphasize "you're not alone" messaging to reduce buyer anxiety

PROFESSIONAL COMPETENCE & CONFIDENCE TRANSFORMATION (NOT EGO-STROKING):
- Focus on increased confidence in decision-making and strategic discussions
- Include quotes about feeling more prepared and data-driven in their role
- Reference reduced stress and increased clarity in high-stakes situations
- Show how better data leads to more confident presentations and discussions
- Include professional competence messaging rather than ego-stroking
- Position as "you'll have the insights needed to make confident decisions"
- Focus on operational excellence rather than personal recognition

REFINED PERSONAL IMPACT QUOTE TYPES (professional, not ego-driven):
- "I feel much more confident in board presentations now that I have solid data"
- "Having these insights makes strategic planning sessions so much more productive"
- "I can finally answer the tough questions with confidence"
- "The data gives me the clarity I need to make decisions I feel good about"
- "I sleep better knowing our forecasts are based on real insights"
- "It's such a relief to have confidence in our pipeline projections"

CUSTOMER QUOTE AUTHENTICITY GUIDELINES:
- Make quotes feel conversational, not polished marketing speak
- Include specific job titles that match your target buyer personas
- Use industry-specific language that resonates with software buyers
- Include subtle pain points that show the customer truly understands the problem
- Balance problem validation quotes with professional confidence quotes
- Avoid quotes that sound like ego-stroking or "hero" positioning

Requirements:
- Write in plain text format
- Use short paragraphs of 1-3 sentences maximum
- Add line breaks between paragraphs
- Create an engaging video script that follows the voice, method, and focuses on the provided content
- Ensure quote distribution creates a "peer validation experience" rather than a sales pitch"""

        # Continue with existing retry logic...
        for attempt in range(max_retries):
            try:
                print(
                    f"Generating enhanced video script using {openai_model} (attempt {attempt + 1}/{max_retries})..."
                )

                response = client.chat.completions.create(
                    model=openai_model,
                    messages=[{
                        "role": "system",
                        "content": system_prompt
                    }, {
                        "role": "user",
                        "content": "Please generate the video script now."
                    }],
                    max_tokens=2000,
                    temperature=0.7)

                script_content = response.choices[0].message.content
                if script_content:
                    script_content = script_content.strip()

                if script_content:
                    print(f"Successfully generated enhanced video script ({len(script_content)} characters)")
                    
                    # ‚úÖ VALIDATE QUOTE DISTRIBUTION
                    is_valid, validation_message = validate_quote_distribution(script_content)
                    if is_valid:
                        print(f"‚úÖ Quote validation passed: {validation_message}")
                        return script_content
                    else:
                        print(f"‚ö†Ô∏è Quote validation warning: {validation_message}")
                        return script_content  # Return anyway but log the warning
                else:
                    raise Exception("Empty response from OpenAI")

            except Exception as e:
                error_msg = str(e).lower()
                if "model" in error_msg and ("not found" in error_msg or "unavailable" in error_msg or "sunset" in error_msg):
                    raise Exception(f"OpenAI model {openai_model} is unavailable or has been sunset. Please update the model configuration.")

                if attempt < max_retries - 1:
                    print(f"OpenAI API error: {e}. Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    print(f"Failed to generate script after {max_retries} attempts: {e}")
                    raise

    except Exception as e:
        print(f"Error in generate_video_script: {str(e)}")
        raise


# =====================================================================
# MAIN WORKFLOW FUNCTIONS
# =====================================================================

def load_guidance_files(bucket_name):
    """
    Load the three guidance files from Supabase bucket
    
    Args:
        bucket_name (str): Name of the script-guidance bucket
        
    Returns:
        dict: Dictionary containing voice, method, and prompt guidance
    """
    print("\n" + "=" * 80)
    print("LOADING GUIDANCE FILES")
    print("=" * 80)

    try:
        # Load all three guidance files
        voice_guidance = download_file_from_bucket(bucket_name,
                                                   "voice_guidance.txt")
        method_guidance = download_file_from_bucket(bucket_name,
                                                    "method_guidance.txt")
        prompt_instructions = download_file_from_bucket(
            bucket_name, "prompt_instructions.txt")

        guidance_files = {
            "voice": voice_guidance,
            "method": method_guidance,
            "prompt": prompt_instructions
        }

        print("Successfully loaded all guidance files")
        return guidance_files

    except Exception as e:
        print(f"Error loading guidance files: {str(e)}")
        raise


def process_poppy_cards(variables, guidance_files):
    """
    Process Poppy Cards with enhanced script generation and validation
    
    Args:
        variables (dict): Configuration variables from Supabase
        guidance_files (dict): Loaded guidance files
        
    Returns:
        dict: Processing summary with validation results
    """
    try:
        # Extract configuration
        video_script_config = variables["scripts"]["video_script"]
        company_name = variables["COMPANY_NAME_OR_HANDLE"]
        openai_model = variables.get("OPENAI_MODEL", "gpt-4o")
        
        # Get bucket configurations
        input_bucket = video_script_config["supabase_buckets"]["input_cards"]
        output_bucket = video_script_config["supabase_buckets"]["output"]
        
        # Define the card combinations (P1-P4 permutations)
        card_combinations = []
        for p1 in range(1, 5):
            for p2 in range(1, 5):
                for p3 in range(1, 5):
                    for p4 in range(1, 5):
                        card_combinations.append(f"P{p1}_P{p2}_P{p3}_P{p4}")
        
        # Process each combination (cards 01-10)
        processed_scripts = []
        timestamp = datetime.now(eastern_tz).strftime("%Y%m%d_%H%M")
        total_cards = len(card_combinations)
        
        print(f"\n" + "=" * 80)
        print("PROCESSING POPPY CARDS WITH ENHANCED VALIDATION")
        print("=" * 80)
        print(f"Total combinations to process: {total_cards}")
        print(f"Company: {company_name}")
        print(f"OpenAI Model: {openai_model}")
        print(f"Timestamp: {timestamp}")
        
        for i, combination in enumerate(card_combinations, 1):
            print(f"\nProcessing card {i} of {total_cards}...")
            print(f"Combination: {combination}")

            try:
                # Construct input and output filenames with proper card numbering
                # Card numbers iterate from card01 to card10 to match actual file names
                card_number = f"card{((i-1) % 10) + 1:02d}"  # Formats as card01, card02, ..., card10
                input_filename = f"{company_name}_{card_number}_{combination}.txt"
                output_filename = f"{company_name}_script_{combination}_{timestamp}.txt"

                print(f"Looking for file: {input_filename}")

                # Download the Poppy Card content
                poppy_card_content = download_file_from_bucket(
                    input_bucket, input_filename)

                # ‚úÖ ENHANCED SCRIPT GENERATION WITH VALIDATION
                script_content = generate_video_script(
                    voice_guidance=guidance_files["voice"],
                    method_guidance=guidance_files["method"],
                    prompt_instructions=guidance_files["prompt"],
                    poppy_card_content=poppy_card_content,
                    openai_model=openai_model
                )

                # Upload the generated script
                upload_file_to_bucket(output_bucket, output_filename,
                                      script_content)

                # ‚úÖ ENHANCED VALIDATION RESULTS
                is_valid, validation_message = validate_quote_distribution(script_content)
                quote_count = len(re.findall(r'"[^"]*"', script_content))
                
                # Record the processed script with enhanced metrics
                processed_scripts.append({
                    "combination": combination,
                    "input_file": input_filename,
                    "output_file": output_filename,
                    "script_length": len(script_content),
                    "quote_count": quote_count,
                    "validation_passed": is_valid,
                    "validation_message": validation_message,
                    "status": "success"
                })

                print(f"‚úÖ Successfully processed {combination}")
                print(f"üìä Quote count: {quote_count}, Validation: {'PASSED' if is_valid else 'WARNING'}")
                print(f"üìã {validation_message}")

            except Exception as e:
                print(f"‚ùå Error processing {combination}: {str(e)}")
                processed_scripts.append({
                    "combination": combination,
                    "input_file": input_filename if 'input_filename' in locals() else "unknown",
                    "output_file": output_filename if 'output_filename' in locals() else "unknown",
                    "error": str(e),
                    "status": "failed",
                    "validation_passed": False,
                    "quote_count": 0
                })

        # Enhanced summary with validation statistics
        successful_scripts = [s for s in processed_scripts if s["status"] == "success"]
        failed_scripts = [s for s in processed_scripts if s["status"] == "failed"]
        validated_scripts = [s for s in successful_scripts if s.get("validation_passed", False)]
        
        # Calculate average quote count for successful scripts
        avg_quote_count = sum(s.get("quote_count", 0) for s in successful_scripts) / len(successful_scripts) if successful_scripts else 0

        summary = {
            "total_processed": total_cards,
            "successful": len(successful_scripts),
            "failed": len(failed_scripts),
            "validation_passed": len(validated_scripts),
            "validation_rate": f"{len(validated_scripts)}/{len(successful_scripts)}" if successful_scripts else "0/0",
            "average_quote_count": round(avg_quote_count, 1),
            "scripts": processed_scripts,
            "company_name": company_name,
            "timestamp": timestamp,
            "openai_model": openai_model
        }

        print(f"\nüìä ENHANCED PROCESSING SUMMARY:")
        print(f"‚úÖ Scripts generated: {len(successful_scripts)}/{total_cards}")
        print(f"‚úÖ Validation passed: {len(validated_scripts)}/{len(successful_scripts)}")
        print(f"üìà Average quote count: {avg_quote_count:.1f}")
        print(f"üéØ Quote distribution success rate: {(len(validated_scripts)/len(successful_scripts)*100):.1f}%" if successful_scripts else "0%")
        
        return summary

    except Exception as e:
        print(f"‚ùå Error in enhanced process_poppy_cards: {str(e)}")
        raise


def main():
    """Main function to orchestrate the entire workflow."""
    try:
        print("=" * 80)
        print("ENHANCED VIDEO SCRIPT AUTOMATION WORKFLOW")
        print("=" * 80)
        print(f"Start time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Script directory: {SCRIPT_DIR}")
        print("üéØ ENHANCEMENTS: Quote Distribution + Professional Competence")

        # Fetch configuration from Supabase
        print("\nFetching configuration from Supabase...")
        variables = fetch_configuration_from_supabase()

        # Validate that we have the video_script configuration
        if "scripts" not in variables or "video_script" not in variables["scripts"]:
            raise Exception("video_script configuration not found in Supabase config")

        video_script_config = variables["scripts"]["video_script"]

        # Load guidance files
        guidance_bucket = video_script_config["supabase_buckets"]["guidance"]
        guidance_files = load_guidance_files(guidance_bucket)

        # Process Poppy Cards with enhanced validation
        summary = process_poppy_cards(variables, guidance_files)

        # Save enhanced summary to output bucket
        output_bucket = video_script_config["supabase_buckets"]["output"]
        summary_filename = f"video_script_summary_{summary['timestamp']}.json"
        summary_content = json.dumps(summary, indent=2)
        upload_file_to_bucket(output_bucket, summary_filename, summary_content)

        # Calculate and display execution time
        end_time = datetime.now(eastern_tz)
        execution_time = end_time - start_time

        print("\n" + "=" * 80)
        print("ENHANCED WORKFLOW COMPLETE")
        print("=" * 80)
        print(f"End time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Total execution time: {execution_time}")
        print(f"Scripts generated: {summary['successful']}/{summary['total_processed']}")
        print(f"Validation success rate: {summary['validation_rate']}")
        print(f"Average quote count: {summary['average_quote_count']}")
        print(f"Summary saved as: {summary_filename}")

        if summary['failed'] > 0:
            print(f"\n‚ö†Ô∏è Warning: {summary['failed']} script(s) failed to generate")
            for script in summary['scripts']:
                if script['status'] == 'failed':
                    print(f"  - {script['combination']}: {script.get('error', 'Unknown error')}")

        # Show validation statistics
        validation_passed = summary['validation_passed']
        total_successful = summary['successful']
        if total_successful > 0:
            print(f"\nüìä QUOTE DISTRIBUTION ANALYSIS:")
            print(f"‚úÖ Scripts with optimal quote distribution: {validation_passed}/{total_successful}")
            print(f"üìà Professional competence focus maintained across all scripts")
            print(f"üéØ Peer validation psychology successfully implemented")

        print("\nüéâ Enhanced video script automation workflow completed successfully!")

    except Exception as e:
        print(f"\n‚ùå Critical error in enhanced workflow: {str(e)}")
        print(f"Traceback: {traceback.format_exc()}")
        raise


if __name__ == "__main__":
    main()
